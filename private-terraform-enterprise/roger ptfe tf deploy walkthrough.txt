Attached are my tfvars files for deploying PTFE on Ubuntu with external services in AWS. The first file, network.auto.tfvars, is for stage 1.  I had forgotten to include aws_region, bucket_name, and kms_key_arn variables in network.auto.tfvars.example.  I will fix that in the repository. The second file, roger-ptfe-ubuntu.auto.tfvars, is for stage 2 of my two-stage deployment process. I suggest renaming that to <name>-ptfe.ubuntu.auto.tfvars.

If you guys want to skip straight to stage 2, you can use many of the values in the roger-ptfe-ubuntu.auto.tfvars file, especially the vpc_id, subnet_ids, and security_group_id variables.  If you do skip to stage 2, then you won't be using the network.auto.tfvars file.  But if you don't skip stage 1, be sure to change the values in it and that the namespace in your two tfvars files match, that bucket_name and kms_key_arn in network.auto.tfvars match  source_bucket_name and s3_sse_kms_key_id respectively in your <name>-ptfe.ubuntu.auto.tfvars file.

You could also use the following variable values if you would rather not create your own S3 source bucket, ACM cert, and KMS key:
ssl_certificate_arn variable with value "arn:aws:acm:us-east-1:753646501470:certificate/30ae2625-e1c6-42c4-9792-3eed4a1f4314" which is for the wildcard certificate *.hashidemos.io
source_bucket_name with value "roger-ptfe-source" which already has the PTFE replicated license file you could use.
ptfe_license with value "rogerberlind-hashicorp-se-12312019.rli" which is the actual license file in that bucket
s3_sse_kms_key_id with value "00c892e8-40c4-4048-a650-0f755876503d" which is the KMS key that is used to encrypt both the source bucket and the runtime bucket
However, you should change other variables that have "roger" in their values including namespace, ssh_key_name, owner, hostname, s3_bucket, initial_admin_username, initial_admin_email, initial_org_name, and initial_org_email.

Here are the steps to clone the TF code and run both stages 1 and 2 after first installing Terraform OSS 0.11.13 on your laptop.  If you don't want to use my KMS key, then create one and provide its ID in both tfvars files before starting stage 1.  Be sure to also have an AWS ssh key pair that you can use in stage 2; you will need it to SSH to the PTFE instance.

Clone the Repository and switch to right branch:
On your laptop, navigate to a directory into which you want to deploy my TF code.  You might already have a GitHub/hashicorp directory.  If so, that would be perfect because cloning the code in the next step will create a private-terraform-enterprise directory under that.
git clone https://github.com/hashicorp/private-terraform-enterprise.git
cd private-terraform-enterprise
git checkout automated-aws-pes-installation (to switch to my branch)
Stage 1:
cd examples/aws/network
cp network.auto.tfvars.example network.auto.tfvars
Edit network.auto.tfvars and set namespace to "<name>-ptfe", provide valid values for all the variables, and save the file.
export AWS_ACCESS_KEY_ID=<your_aws_key>
export AWS_SECRET_ACCESS_KEY=<your_aws_secret_key>
export AWS_DEFAULT_REGION=us-east-1
terraform init
terraform apply (and type "yes" when prompted).  The apply takes at most 3 minutes.
Note the security_group_id, subnet_ids, and vpc_id outputs which you will need in stage 2.
cd .. (to go back to the examples/aws directory)
Add your PTFE license file to your PTFE source bucket (the one created in stage 1). You can do this in the AWS Console.
Stage 2:
Make sure you are in the examples/aws directory of the cloned repository.
If you skipped stage 1, do steps 4-6 of that stage to export your AWS keys and default region.
Edit <name>-ptfe.ubuntu.auto.tfvars to set namespace, vpc_id, subnet_ids, security_group_id, and source_bucket_name to match the namespace and bucket_name you used in network.auto.tfvars and the outputs from stage 1.
Also change various variables to use your name instead of "roger", but keep the ones I mentioned above if you skipped stage 1.
terraform init
terraform apply (and type "yes" when prompted). The apply takes about 15 minutes.  Most of the time is spent creating the PostgreSQL database in RDS.
After you see outputs for the apply, visit the AWS Console, find your <name>-ptfe-1 instance. These outputs will include: db_endpoint, ptfe_fqdn, ptfe_private_dns, ptfe_private_ip, ptfe_public_dns, ptfe_public_ip. (I only give the IPs and DNS addresses for the primary instance.)
Click the Connect button and copy the SSH connection command.
Type that command in a shell that contains your SSH private key from your AWS key pair and connect to the primary PTFE instance.
You can now tail the install-ptfe.log with "tail -f install-ptfe.log". Note that it is ok if you see multiple warnings in the log saying something like "curl: (6) Could not resolve host: <name>-ptfe.hashidemos.io".  This just means that the script has run the installer and is testing the availability of the PTFE application with curl every 15 seconds. Of course, if this lasts for more than 5 minutes (as was the case in my test due to the Route53 service issue), then something is wrong.
When the install-ptfe.log stops showing curl calls and instead shows something related to the initial admin user and organization being created, point a browser tab against https://<user>-ptfe.hashidemos.io, type in your username and your password, and you can start using your PTFE server.
Note that you never need to visit the PTFE admin console when deploying with my process.
